{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7690ab9",
   "metadata": {},
   "source": [
    "# TensorFlow practice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed28db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2333a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f05df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edbbec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3897000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this why input_shap=(28, 28)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081e3d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0,0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe8401eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0565a741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the unique values, this is why output dense is 10\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7b06280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2209 - accuracy: 0.9347 - val_loss: 0.1001 - val_accuracy: 0.9693\n",
      "Epoch 2/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0984 - accuracy: 0.9698 - val_loss: 0.0808 - val_accuracy: 0.9731\n",
      "Epoch 3/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0697 - accuracy: 0.9780 - val_loss: 0.0672 - val_accuracy: 0.9786\n",
      "Epoch 4/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.0639 - val_accuracy: 0.9807\n",
      "Epoch 5/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.0686 - val_accuracy: 0.9800\n",
      "Epoch 6/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.0609 - val_accuracy: 0.9817\n",
      "Epoch 7/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0669 - val_accuracy: 0.9818\n",
      "Epoch 8/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0678 - val_accuracy: 0.9818\n",
      "Epoch 9/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0652 - val_accuracy: 0.9833\n",
      "Epoch 10/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0660 - val_accuracy: 0.9833\n",
      "Epoch 11/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0710 - val_accuracy: 0.9826\n",
      "Epoch 12/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0686 - val_accuracy: 0.9838\n",
      "Epoch 13/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0691 - val_accuracy: 0.9833\n",
      "Epoch 14/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0905 - val_accuracy: 0.9801\n",
      "Epoch 15/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0834 - val_accuracy: 0.9824\n",
      "Epoch 16/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.0947 - val_accuracy: 0.9799\n",
      "Epoch 17/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0764 - val_accuracy: 0.9850\n",
      "Epoch 18/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0895 - val_accuracy: 0.9828\n",
      "Epoch 19/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0882 - val_accuracy: 0.9817\n",
      "Epoch 20/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0909 - val_accuracy: 0.9825\n",
      "Epoch 21/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0892 - val_accuracy: 0.9833\n",
      "Epoch 22/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0931 - val_accuracy: 0.9836\n",
      "Epoch 23/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0899 - val_accuracy: 0.9828\n",
      "Epoch 24/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0980 - val_accuracy: 0.9824\n",
      "Epoch 25/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0921 - val_accuracy: 0.9839\n",
      "Epoch 26/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0830 - val_accuracy: 0.9846\n",
      "Epoch 27/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1036 - val_accuracy: 0.9827\n",
      "Epoch 28/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1005 - val_accuracy: 0.9837\n",
      "Epoch 29/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0949 - val_accuracy: 0.9848\n",
      "Epoch 30/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1184 - val_accuracy: 0.9826\n",
      "Epoch 31/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0969 - val_accuracy: 0.9854\n",
      "Epoch 32/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1126 - val_accuracy: 0.9840\n",
      "Epoch 33/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1079 - val_accuracy: 0.9847\n",
      "Epoch 34/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.1133 - val_accuracy: 0.9836\n",
      "Epoch 35/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1087 - val_accuracy: 0.9846\n",
      "Epoch 36/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1212 - val_accuracy: 0.9844\n",
      "Epoch 37/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.1138 - val_accuracy: 0.9839\n",
      "Epoch 38/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1327 - val_accuracy: 0.9821\n",
      "Epoch 39/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1367 - val_accuracy: 0.9813\n",
      "Epoch 40/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1171 - val_accuracy: 0.9846\n",
      "Epoch 41/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1271 - val_accuracy: 0.9838\n",
      "Epoch 42/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1337 - val_accuracy: 0.9832\n",
      "Epoch 43/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1507 - val_accuracy: 0.9839\n",
      "Epoch 44/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1295 - val_accuracy: 0.9855\n",
      "Epoch 45/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1652 - val_accuracy: 0.9823\n",
      "Epoch 46/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1438 - val_accuracy: 0.9843\n",
      "Epoch 47/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.1458 - val_accuracy: 0.9838\n",
      "Epoch 48/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1547 - val_accuracy: 0.9838\n",
      "Epoch 49/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1445 - val_accuracy: 0.9831\n",
      "Epoch 50/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1441 - val_accuracy: 0.9834\n",
      "Epoch 51/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1413 - val_accuracy: 0.9848\n",
      "Epoch 52/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.1463 - val_accuracy: 0.9849\n",
      "Epoch 53/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1517 - val_accuracy: 0.9846\n",
      "Epoch 54/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1434 - val_accuracy: 0.9845\n",
      "Epoch 55/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.1618 - val_accuracy: 0.9833\n",
      "Epoch 56/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1509 - val_accuracy: 0.9839\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.1509 - val_accuracy: 0.9838\n",
      "Epoch 58/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1518 - val_accuracy: 0.9832\n",
      "Epoch 59/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1499 - val_accuracy: 0.9848\n",
      "Epoch 60/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.1535 - val_accuracy: 0.9833\n",
      "Epoch 61/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1509 - val_accuracy: 0.9848\n",
      "Epoch 62/70\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1574 - val_accuracy: 0.9849\n",
      "Epoch 63/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1757 - val_accuracy: 0.9813\n",
      "Epoch 64/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.1596 - val_accuracy: 0.9845\n",
      "Epoch 65/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.1454 - val_accuracy: 0.9848\n",
      "Epoch 66/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1516 - val_accuracy: 0.9855\n",
      "Epoch 67/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.1597 - val_accuracy: 0.9846\n",
      "Epoch 68/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.1758 - val_accuracy: 0.9839\n",
      "Epoch 69/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.1755 - val_accuracy: 0.9842\n",
      "Epoch 70/70\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.1671 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ffba878a20>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=70, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92d3bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18712), started 0:31:40 ago. (Use '!kill 18712' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-156c74c07f7cfe4a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-156c74c07f7cfe4a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf87795",
   "metadata": {},
   "source": [
    "## Using TensorBoard with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b26f7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the same dataset as above, but convert it to tf.data.Dataset to take advantage of batching capabilities:\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
    "test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12bfd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48b5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create stateful metrics that can be used to accumulate values during training and logged at any point:\n",
    "\n",
    "# Define our metrics\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d307fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the training and test functions:\n",
    "def train_step(model, optimizer, x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(y_train, predictions)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14cb1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up summary writers to write the summaries to disk in a different logs directory:\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dab7a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24657772481441498, Accuracy: 92.8116683959961, Test Loss: 0.11517127603292465, Test Accuracy: 96.55999755859375\n",
      "Epoch 2, Loss: 0.10437845438718796, Accuracy: 96.93333435058594, Test Loss: 0.08161076158285141, Test Accuracy: 97.43999481201172\n",
      "Epoch 3, Loss: 0.07145392149686813, Accuracy: 97.86333465576172, Test Loss: 0.07061807811260223, Test Accuracy: 97.75\n",
      "Epoch 4, Loss: 0.054594986140728, Accuracy: 98.24500274658203, Test Loss: 0.06547126919031143, Test Accuracy: 98.00999450683594\n",
      "Epoch 5, Loss: 0.04281660541892052, Accuracy: 98.63333129882812, Test Loss: 0.0613190159201622, Test Accuracy: 98.16999816894531\n",
      "Epoch 6, Loss: 0.03684172034263611, Accuracy: 98.87333679199219, Test Loss: 0.06526137888431549, Test Accuracy: 98.12999725341797\n",
      "Epoch 7, Loss: 0.028544757515192032, Accuracy: 99.08833312988281, Test Loss: 0.06622859835624695, Test Accuracy: 97.98999786376953\n",
      "Epoch 8, Loss: 0.0251532644033432, Accuracy: 99.17500305175781, Test Loss: 0.06602455675601959, Test Accuracy: 97.95999908447266\n"
     ]
    }
   ],
   "source": [
    "model = create_model() # reset our model\n",
    "\n",
    "EPOCHS = 8\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train, y_train) in train_dataset:\n",
    "        train_step(model, optimizer, x_train, y_train)\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for (x_test, y_test) in test_dataset:\n",
    "        test_step(model, x_test, y_test)\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result(), \n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(), \n",
    "                         test_accuracy.result()*100))\n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db3d3437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18468), started 0:29:02 ago. (Use '!kill 18468' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-218010210984dbb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-218010210984dbb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481018d",
   "metadata": {},
   "source": [
    "## Save and reload trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59e2c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"adv_model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f73d4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "adv_model = load_model(\"adv_model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53bca73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloaded model must compile before use\n",
    "adv_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe5373",
   "metadata": {},
   "source": [
    "## evaluate reloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "601a939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 6.2168e-05 - accuracy: 1.0000\n",
      "Normal Neural Network - Loss: 6.216756446519867e-05, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = adv_model.evaluate(\n",
    "    x_test, y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b3841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythonAdv] *",
   "language": "python",
   "name": "conda-env-pythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
