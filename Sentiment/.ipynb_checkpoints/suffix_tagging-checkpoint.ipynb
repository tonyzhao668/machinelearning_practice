{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c441631",
   "metadata": {},
   "source": [
    "## Working with word suffix and tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d38b0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d78b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ffb0b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3708"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nword = \"categories\"\n",
    "suffix_fdist[nword[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1eeec658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nword[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c235d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b38efd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "743506bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df3a8602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0ad17",
   "metadata": {},
   "source": [
    "## Tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f8c0836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tagging\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1354aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['And', 'now', 'for', 'something', 'completely', 'different']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31f9a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "#word tag explanation \n",
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb710c",
   "metadata": {},
   "source": [
    "## working with nltk brown database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b1af774",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b563b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7528a6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'endswith(e)': False}, 'NP$')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "255ff487",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c88eb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17135753356539035"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1939f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AT'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(pos_features('The'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5beecd",
   "metadata": {},
   "source": [
    "## working with brown sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79d527ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i): \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9fcaf250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fe117d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"Atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "968ff241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix(1)': 'y', 'suffix(2)': 'ay', 'suffix(3)': 'day', 'prev-word': 'said'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pos_features(brown.sents()[0], 6) # the 6 is the 6th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7fc5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append( (pos_features(untagged_sent, i), tag) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef6dea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "39848f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "74cf843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                 \"suffix(2)\": sentence[i][-2:],\n",
    "                 \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de5c2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutivePosTagger(nltk.TaggerI): \n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0063237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980528511821975\n"
     ]
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238e23e",
   "metadata": {},
   "source": [
    "## sample function of Enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "afc5a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'eat'), (1, 'sleep'), (2, 'repeat')]\n"
     ]
    }
   ],
   "source": [
    "# index from 0 and element of list into tuple to be in a list\n",
    "l1 = [\"eat\",\"sleep\",\"repeat\"]\n",
    "print(list(enumerate(l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7b89878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = list(enumerate(l1))\n",
    "type(en[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c38083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
