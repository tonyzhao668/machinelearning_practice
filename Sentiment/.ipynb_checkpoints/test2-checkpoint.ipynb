{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee0af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.naive_bayes import ComplementNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# import operator\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a5e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/movie_reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b38c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock destined st century new conan going make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorgeously elaborate continuation lord ring tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes like go movie fun wasabi good place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges something rare issue movie honest keen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary  Sentiment\n",
       "0  rock destined st century new conan going make ...          1\n",
       "1  gorgeously elaborate continuation lord ring tr...          1\n",
       "2                             effective tepid biopic          1\n",
       "3  sometimes like go movie fun wasabi good place ...          1\n",
       "4  emerges something rare issue movie honest keen...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47281138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock destined st century new conan going make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorgeously elaborate continuation lord ring tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes like go movie fun wasabi good place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges something rare issue movie honest keen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>terrible movie people nevertheless find moving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>many definition time waster movie must surely one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>stand crocodile hunter hurried badly cobbled l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>thing look like made home video quickie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>enigma well made dry placid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10662 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Summary  Sentiment\n",
       "0      rock destined st century new conan going make ...          1\n",
       "1      gorgeously elaborate continuation lord ring tr...          1\n",
       "2                                 effective tepid biopic          1\n",
       "3      sometimes like go movie fun wasabi good place ...          1\n",
       "4      emerges something rare issue movie honest keen...          1\n",
       "...                                                  ...        ...\n",
       "10657     terrible movie people nevertheless find moving          0\n",
       "10658  many definition time waster movie must surely one          0\n",
       "10659  stand crocodile hunter hurried badly cobbled l...          0\n",
       "10660            thing look like made home video quickie          0\n",
       "10661                        enigma well made dry placid          0\n",
       "\n",
       "[10662 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep = 'last', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59331b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5330\n",
       "0    5330\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10660, 1) (10660,)\n"
     ]
    }
   ],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = df.drop(\"Sentiment\", axis=1)\n",
    "y = df[\"Sentiment\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80689ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# for row in X.iterrows():\n",
    "#     if n >= 2:\n",
    "#         break\n",
    "#     print(row)\n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3047f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "words_bag = {}\n",
    "\n",
    "#build documents with each review's words and sentiment in tuple and append into doc_list\n",
    "for i in X.index:\n",
    "#     if i >= 1000:\n",
    "#         break\n",
    "    sentence = X[\"Summary\"][i]\n",
    "    res = re.findall(r'\\w+', sentence.lower()) #take only the lower case\n",
    "    res_tuple = (res,)\n",
    "    sent_tuple = (y[i],)\n",
    "    words_sent_tuple = res_tuple + sent_tuple\n",
    "    doc_list.append(words_sent_tuple)\n",
    "    \n",
    "#get the unique words into words_bag\n",
    "    for j in range(len(res)):\n",
    "        if res[j] in words_bag:\n",
    "            words_bag[res[j]] += 1\n",
    "        else:\n",
    "            words_bag[res[j]] = 1\n",
    "#print(words_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16319\n"
     ]
    }
   ],
   "source": [
    "# get the whole words in list\n",
    "words_features = list(words_bag)\n",
    "print(len(words_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b03eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(words_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the doc_list\n",
    "random.shuffle(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87debb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(d_words):\n",
    "    document_words = set(d_words)\n",
    "    features = {}\n",
    "    for word in words_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words) #if in return \"True\" otherwise \"False\".\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c34af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if wanted can working on smaller docs size\n",
    "working_docs = doc_list[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on smaller sized docs\n",
    "#featuresets = [(document_features(d), c) for (d,c) in working_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier\n",
    "featuresets = [(document_features(d), c) for (d,c) in doc_list]\n",
    "train_set, test_set = featuresets[3200:], featuresets[:3200] #80% train 20% test, total 16319\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f64e3",
   "metadata": {},
   "source": [
    "## Accuracy assessment of the classifier trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9250d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7546875\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0faab",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c46b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on smaller sized docs\n",
    "featuresets2 = [(document_features(d), c) for (d,c) in working_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original divided into 3 groups,train set, test set, and development set\n",
    "train_set2 = featuresets2[1500:]\n",
    "devtest_set = featuresets2[500:1500]\n",
    "test_set2 = featuresets2[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77153070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier2 with smaller size docs\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier2\n",
    "print(nltk.classify.accuracy(classifier2, test_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "rights = []\n",
    "for (d, c) in devtest_set:\n",
    "    guess = classifier2.classify(document_features(d))\n",
    "    if guess != c:\n",
    "        errors.append( (c, guess) ) #tuple as element appended\n",
    "    else:\n",
    "        rights.append((c, guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5380b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9decc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbb0f6",
   "metadata": {},
   "source": [
    "## save and load the trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'bayesclass_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'bayesclass_model2_smallsize.sav'\n",
    "pickle.dump(classifier2, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3823d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "classifier = pickle.load(open(filename, 'rb'))\n",
    "classifier2 = pickle.load(open(filename2, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1ce64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce988d9b4cf00875e03da43ec664a94334de381b734a3b7fe7b6cfed42b24ab3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
